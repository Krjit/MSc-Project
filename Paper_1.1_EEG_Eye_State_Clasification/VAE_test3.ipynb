{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv('EEG_Eye_State.csv')\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "su = SMOTE(random_state=42)\n",
    "X, y= su.fit_resample(X, y)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(data.drop('Class', axis=1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14980 entries, 0 to 14979\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      14980 non-null  float64\n",
      " 1   V2      14980 non-null  float64\n",
      " 2   V3      14980 non-null  float64\n",
      " 3   V4      14980 non-null  float64\n",
      " 4   V5      14980 non-null  float64\n",
      " 5   V6      14980 non-null  float64\n",
      " 6   V7      14980 non-null  float64\n",
      " 7   V8      14980 non-null  float64\n",
      " 8   V9      14980 non-null  float64\n",
      " 9   V10     14980 non-null  float64\n",
      " 10  V11     14980 non-null  float64\n",
      " 11  V12     14980 non-null  float64\n",
      " 12  V13     14980 non-null  float64\n",
      " 13  V14     14980 non-null  float64\n",
      " 14  Class   14980 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8257\n",
       "0    6723\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8257\n",
       "0    8257\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE architecture\n",
    "original_dim = X_train.shape[1]\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "inputs = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "h = Dense(intermediate_dim, activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder network\n",
    "h_decoded = Dense(intermediate_dim, activation='relu')(z)\n",
    "h_decoded = Dense(intermediate_dim, activation='relu')(h_decoded)\n",
    "x_decoded = Dense(original_dim, activation='linear')(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE model\n",
    "vae = Model(inputs, x_decoded)\n",
    "reconst_loss = original_dim * keras.losses.binary_crossentropy(inputs, x_decoded) \n",
    "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconst_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "104/104 [==============================] - 2s 9ms/step - loss: 5.1456 - val_loss: 206863.3281\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 3.1755 - val_loss: 2874503.0000\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.7119 - val_loss: 45019.7695\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.6377 - val_loss: 129443.2031\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.6353 - val_loss: 17689.9551\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5986 - val_loss: 74098984.0000\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5802 - val_loss: 362333.3125\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5807 - val_loss: 851639.6250\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5645 - val_loss: 440721472.0000\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5608 - val_loss: 4442984.5000\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5515 - val_loss: 163761.8594\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5502 - val_loss: 10333.1152\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.5387 - val_loss: 230.0012\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.4826 - val_loss: 98644.2500\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3552 - val_loss: 1196045.1250\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3497 - val_loss: 78109.8828\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3439 - val_loss: 680.2273\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3421 - val_loss: 81583.0938\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3375 - val_loss: 1679105.7500\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3353 - val_loss: 13900059.0000\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3333 - val_loss: 41700168.0000\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3308 - val_loss: 1024801.7500\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 2.3296 - val_loss: 68714.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5a3a8d450>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "# Train the VAE\n",
    "vae.fit(X_train, X_train,\n",
    "        shuffle=True,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_test, X_test),\n",
    "        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.summary()\n",
    "# len(vae.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 0s 1ms/step\n",
      "104/104 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the encoder to get latent variables for each data point\n",
    "# encoder = Model(inputs, z_mean)\n",
    "encoder = Sequential()\n",
    "for i in range((len(vae.layers)-15)//2):\n",
    "\tencoder.add(vae.layers[i])\n",
    "\t\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13211, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a classifier on top of the encoded data\n",
    "# clf_inputs = Input(shape=(latent_dim,))\n",
    "# clf_h = Dense(32, activation='relu')(clf_inputs)\n",
    "# clf_h = Dense(16, activation='relu')(clf_h)\n",
    "# clf_h = Dense(8, activation='relu')(clf_h)\n",
    "# clf_outputs = Dense(1, activation='sigmoid')(clf_h)\n",
    "# clf = Model(clf_inputs, clf_outputs)\n",
    "\n",
    "from keras.constraints import MaxNorm\n",
    "clf = Sequential()\n",
    "clf.add(Dense(32, input_shape=(latent_dim,), activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(Dense(8, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 - 1s - loss: 0.2501 - accuracy: 0.5000 - val_loss: 0.2500 - val_accuracy: 0.4989 - 832ms/epoch - 11ms/step\n",
      "Epoch 2/50\n",
      "78/78 - 0s - loss: 0.2502 - accuracy: 0.4965 - val_loss: 0.2500 - val_accuracy: 0.5011 - 330ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.5007 - val_loss: 0.2500 - val_accuracy: 0.5011 - 322ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.4990 - val_loss: 0.2500 - val_accuracy: 0.5011 - 312ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.4979 - val_loss: 0.2500 - val_accuracy: 0.5011 - 322ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.4994 - val_loss: 0.2500 - val_accuracy: 0.5011 - 321ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.5056 - val_loss: 0.2501 - val_accuracy: 0.4989 - 313ms/epoch - 4ms/step\n",
      "Epoch 8/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.5001 - val_loss: 0.2500 - val_accuracy: 0.4989 - 319ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.5014 - val_loss: 0.2500 - val_accuracy: 0.5011 - 319ms/epoch - 4ms/step\n",
      "Epoch 10/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.4952 - val_loss: 0.2500 - val_accuracy: 0.4989 - 319ms/epoch - 4ms/step\n",
      "Epoch 11/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.4932 - val_loss: 0.2500 - val_accuracy: 0.5011 - 318ms/epoch - 4ms/step\n",
      "Epoch 12/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.4950 - val_loss: 0.2500 - val_accuracy: 0.4989 - 308ms/epoch - 4ms/step\n",
      "Epoch 13/50\n",
      "78/78 - 0s - loss: 0.2501 - accuracy: 0.4938 - val_loss: 0.2500 - val_accuracy: 0.4989 - 308ms/epoch - 4ms/step\n",
      "Epoch 14/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.4963 - val_loss: 0.2500 - val_accuracy: 0.4989 - 321ms/epoch - 4ms/step\n",
      "Epoch 15/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.5027 - val_loss: 0.2500 - val_accuracy: 0.5011 - 343ms/epoch - 4ms/step\n",
      "Epoch 16/50\n",
      "78/78 - 0s - loss: 0.2500 - accuracy: 0.5021 - val_loss: 0.2501 - val_accuracy: 0.5011 - 332ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5a6fef400>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the encoded data\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "clf.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "clf.fit(X_train_encoded, \n",
    "        y_train, epochs=50, \n",
    "        batch_size=128, \n",
    "        validation_split=0.25, \n",
    "        verbose=2,\n",
    "        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 - 0s - loss: 0.2501 - accuracy: 0.5017 - 200ms/epoch - 2ms/step\n",
      "Test accuracy: 0.5016651749610901\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the test set\n",
    "test_loss, test_acc = clf.evaluate(X_test_encoded, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on new data\n",
    "predictions = clf.predict(X_test_encoded)\n",
    "\n",
    "# Convert the predictions to binary values\n",
    "predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1646\n",
      "           1       0.50      1.00      0.67      1657\n",
      "\n",
      "    accuracy                           0.50      3303\n",
      "   macro avg       0.25      0.50      0.33      3303\n",
      "weighted avg       0.25      0.50      0.34      3303\n",
      "\n",
      "Kapaa: 0.0\n",
      "\n",
      "Confusion_matrix: \n",
      " [[   0 1646]\n",
      " [   0 1657]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Kapaa:\", cohen_kappa_score(y_test, predictions))\n",
    "print(\"\\nConfusion_matrix: \\n\", confusion_matrix(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306bc892ea967f84a5c48ab9b18b93ea1316fb028bb2c602ea80ae04c43397d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
