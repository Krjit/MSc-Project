{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Common Libraies\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# For Machine learning Model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/91629/OneDrive/MSC 4TH SEM\\MSC_THESIS_of_Kumarjit_Gupta_(Roll-573)\")\n",
    "\n",
    "# Own Library\n",
    "# from Own_Library.Classification_Reports import classification_reports\n",
    "from Own_Library.ClassifierAnalysis import find_reports, best_find, Splitings, Feature_Selections, Cross_Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into the memory\n",
    "data = pd.read_csv('Dataset\\data-ori_clear_PTC.csv')\n",
    "\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select independent features\n",
    "X = data.iloc[:,:-1]#.values\n",
    "\n",
    "# Select Dependent features\n",
    "y = data.iloc[:,-1]#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [0.1, 0.2, 0.25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()\n",
    "algoname1= 'Logistic Regression'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. All Split Checking\n",
    "- 1.1. Train 90%, Test 10%\n",
    "- 1.2. Train 80%, Test 20%\n",
    "- 1.3. Train 75%, Test 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 =['F1_Score', 'Diagnostic_Odds_Ratio', 'Critical_Success_Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_split1, plotdf_split1 = Splitings(model1, X, y, splits, metrics1, algoname1, dim =False)\n",
    "print('Spliting Classification Metrics DataFrame:') \n",
    "plotdf_split1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the best spilit is (90,10) split for better metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ALL Feature section checking\n",
    "- 2.1. Without Feature Selection \n",
    "- 2.2. Pearson Correlation\n",
    "- 2.3. Mutual info classif\n",
    "- 2.4. Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2= ['F1_Measure', 'Specificity', 'Negative_Predictive_Value']\n",
    "featX1, plotdf_fs2, del_cols1 = Feature_Selections(model1, data, best_split1, metrics2, algoname1, dim = False)\n",
    "print(\"Best Independent vector's Shape by feature Selection:\", featX1.shape)\n",
    "print(\"Deleted Columns:\", del_cols1)\n",
    "print(\"Feature Selections Classification Metrics DataFrame:\")\n",
    "plotdf_fs2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. All CV CHECKING\n",
    "- 3.1.  Kfold\n",
    "- 3.2.  Stratified Kfold\n",
    "- 3.3.  Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = ['balanced_accuracy', 'accuracy', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv1, plotdf_cv1 = Cross_Validations(model1, featX1, y, best_split1, metrics2, algoname1, dim =False)\n",
    "print('Spliting Classification Metrics DataFrame:') \n",
    "plotdf_cv1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ALL Hyperparameter tuning checking\n",
    "- 4.1. Randomized Search CV (Normal Optimization)\n",
    "- 4.2. HyperOpt (Bayesian Optimization)\n",
    "- 4.3. Optuna (Asynchronous Distributed Optimization)\n",
    "- 4.4. Cuckoo Search (NIOA) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Using Randomized Search Cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics3 = ['precision_macro', 'recall_macro', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Hyperparameters\n",
    "param_grid = {'C': uniform(0.001, 100), #[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'fit_intercept':[True, False],\n",
    "            'max_iter':randint(100, 300),#[100, 200, 300],\n",
    "             }\n",
    "\n",
    "# Random search for best hyperparameters\n",
    "search = RandomizedSearchCV(estimator=model1, \n",
    "                            param_distributions=param_grid, \n",
    "                            cv=best_cv1,\n",
    "                            n_iter=10, \n",
    "                            scoring=metrics3,\n",
    "                            refit= False,\n",
    "                            n_jobs=2,\n",
    "                            #  return_train_score=True,\n",
    "                            verbose=4)  \n",
    "\n",
    "search.fit(X, y)\n",
    "\n",
    "# Best parameters for Logistic regression classifier\n",
    "# search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with best model\n",
    "pd.DataFrame(search.cv_results_)['mean_test_precision_macro']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Using HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# define parameter space\n",
    "space = {\n",
    "    \"C\": hp.uniform(\"C\",0.0, 100.0),\n",
    "    \"fit_intercept\":hp.choice(\"fit_intercept\", [True, False]),\n",
    "    \"max_iter\":  hp.randint(\"max_iter\", 100, 300),\n",
    "    \"class_weight\": hp.choice(\"class_weight\", ['balanced'])#, {0: 1, 1: 2}, {0: 1, 1: 4}, {0: 1, 1: 5}]),\n",
    "}\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# space = {\n",
    "#     \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "#     \"max_depth\": hp.randint(\"max_depth\", 1, 15),\n",
    "#     \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "# }\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(params):\n",
    "    clf = LogisticRegression(**params, n_jobs=-1, random_state=42)\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"model\": clf, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "# Fine tune the model\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=10, \n",
    "    trials=trials\n",
    ")\n",
    "# best.best_params_\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperopt= trials.results[np.argmin([r['loss'] for r in trials.results])]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperopt.fit(X, y)\n",
    "y_pred = best_hyperopt.predict(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib \n",
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# define the search space and the objecive function\n",
    "def objective(trial):\n",
    "    # # Define the search space\n",
    "    # criterions = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    # max_depths = trial.suggest_int('max_depth', 1, 9, 1)\n",
    "    # n_estimators = trial.suggest_int('n_estimators', 100, 1000, 100)\n",
    "\n",
    "    # clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "    #                              criterion=criterions,\n",
    "    #                              max_depth=max_depths,\n",
    "    #                              n_jobs=-1)\n",
    "    params = {\n",
    "    'C' : trial.suggest_float(\"C\", 1e-2, 1),\n",
    "    'fit_intercept' : trial.suggest_categorical('fit_intercept' , [True, False]),\n",
    "    \"max_iter\":  trial.suggest_int(\"max_iter\", 100, 300, 1),\n",
    "    # \"class_weight\": trial.suggest_categorical(\"class_weight\", [{0: 2, 1: 3}]), #, {0: 1, 1: 2}, {0: 1, 1: 4}, {0: 1, 1: 5}\n",
    "    'solver' : trial.suggest_categorical('solver' , ['lbfgs','liblinear']),\n",
    "    # \"n_jobs\":-1\n",
    "    }\n",
    "\n",
    "    clf = LogisticRegression(**params, random_state=42)\n",
    "    score = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study object and pass the objective function to method optimize()\n",
    "study = optuna.create_study(study_name=\"LogiticReg_optimization\",\n",
    "                            direction=\"maximize\",\n",
    "                            sampler=TPESampler())\n",
    "\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters \n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optuna = LogisticRegression(**study.best_params)\n",
    "best_optuna.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from niapy.algorithms.basic import ParticleSwarmAlgorithm, CuckooSearch\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': range(20, 100, 20),\n",
    "#     'max_depth': range(2, 40, 2),\n",
    "#     'min_samples_split': range(2, 20, 2),\n",
    "#     'max_features': [\"sqrt\", \"log2\"],\n",
    "# }\n",
    "\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            # 'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'fit_intercept':[True, False],\n",
    "            'max_iter':range(100, 300, 20),#[100, 200, 300],\n",
    "              # 'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 4}, {0: 1, 1: 5}]\n",
    "             }\n",
    "\n",
    "# # Hyperparameters\n",
    "# param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#               'kernel': ['linear', 'rbf', 'poly'],\n",
    "#               'degree':[0, 1, 2, 3, 4, 5, 6]\n",
    "#              }\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "algorithm = ParticleSwarmAlgorithm() # when custom algorithm is provided random_state is ignored\n",
    "algorithm.set_parameters(NP=50, Ts=5, Mr=0.25)\n",
    "\n",
    "nia_search = NatureInspiredSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    algorithm=algorithm,\n",
    "    population_size=50,\n",
    "    max_n_gen=30,\n",
    "    max_stagnating_gen=20,\n",
    "    scoring= 'accuracy',\n",
    "    verbose = 2,\n",
    "    runs=3,\n",
    ")\n",
    "\n",
    "nia_search.fit(X, y)\n",
    "\n",
    "# The most optimal parameters are stored in:\n",
    "# nia_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(**nia_search.best_params_, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# plt=reload(plt)\n",
    "# fpr = {}\n",
    "# tpr = {}\n",
    "# thresh = {}\n",
    "# roc_auc = {}\n",
    "# color = ['orange', 'green', 'blue', 'yellow', 'red', 'violet']\n",
    "# category = ['outcare', 'incare']\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# for i in range(len(category)):\n",
    "#     fpr[i], tpr[i], thresh[i] = roc_curve(\n",
    "#         y_test, y_pred, pos_label=i)\n",
    "#     roc_auc[i] = np.round(auc(fpr[i], tpr[i]), 4)\n",
    "#     plt.plot(fpr[i], tpr[i], linestyle='-', color=color[i],\n",
    "#              label=(\"{},(area={})\".format(category[i], roc_auc[i])))\n",
    "    \n",
    "# plt.title('Multiclass ROC curve')\n",
    "# plt.xlabel('False_Positive_Rate')\n",
    "# plt.ylabel('True Positive rate')\n",
    "# plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306bc892ea967f84a5c48ab9b18b93ea1316fb028bb2c602ea80ae04c43397d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
